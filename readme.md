# Flanbot - A Transformer based Chatbot to answer Science Questions 

## Introduction
The task is to forge an ğŸ’¬NLP chatbot that doesnâ€™t just answer, but masters science-related questions.

## Model Selection: Why flan-t5-base?

I chose `flan-t5-base` for creating the chatbot due to several reasons:

1. **Versatility**: T5 (Text-to-Text Transfer Transformer) is a versatile model that can handle a variety of NLP tasks. This makes it a great choice for a chatbot that needs to understand and generate human-like responses.

2. **Pre-training**: `flan-t5-base` is pre-trained on a large corpus of text, which gives it a good understanding of language semantics and syntax. This is crucial for generating accurate and contextually relevant responses.

3. **Fine-tuning capabilities**: it can be fine-tuned on a specific task or domain. In our case, we can fine-tune it on a dataset of science-related questions and answers to make it a master in this domain.

4. **Performance**: T5 has shown excellent performance in various NLP benchmarks, which gives us confidence in its ability to handle our task effectively.


## Deployment Options
The application can be executed in two different ways:
* locally by running the `start.sh` 
* on in a docker container using `Dockerfile` (preferred)

## Proving Your Mettle
* Submit your masterpiece on GitHub. We want the link within **1 week, not a second more**.
* Go the extra mile and include a video where you walk us through your solution, showcasing 
it in live action. 
* We want to see not just what you've created but also how you envisioned and executed it


## This Is It
We're not just evaluating a project; we're judging your potential to revolutionize our 
landscape. A half-baked app wonâ€™t cut it.

We're zeroing in on:
* ğŸ‘ Exceptional documentation.
* ğŸ‘ Code that speaks volumes.
* ğŸ‘ Inventiveness that dazzles.
* ğŸ‘ A problem-solving beast.
* ğŸ‘ Unwavering adherence to the brief